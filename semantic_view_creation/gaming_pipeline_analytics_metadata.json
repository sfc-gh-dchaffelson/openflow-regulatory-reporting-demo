{
  "semantic_yaml": "name: gaming_pipeline_analytics\ndescription: Analytics for the BOE Gaming regulatory pipeline. Tracks batch processing\n  status, latency metrics, and error rates across the data flow from Postgres CDC\n  through Snowflake Dynamic Tables to SFTP delivery.\ntables:\n  - name: REGULATORY_BATCHES\n    base_table:\n      database: DEDEMO\n      schema: GAMING\n      table: REGULATORY_BATCHES\n    primary_key:\n      columns:\n        - BATCH_ID\n    dimensions:\n      - name: BATCH_ID\n        expr: BATCH_ID\n        data_type: VARCHAR\n      - name: OPERATOR_ID\n        expr: OPERATOR_ID\n        data_type: VARCHAR\n      - name: WAREHOUSE_ID\n        expr: WAREHOUSE_ID\n        data_type: VARCHAR\n      - name: TRANSACTION_COUNT\n        expr: TRANSACTION_COUNT\n        data_type: NUMBER\n      - name: GENERATED_XML\n        expr: GENERATED_XML\n        data_type: VARCHAR\n      - name: STATUS\n        expr: STATUS\n        data_type: VARCHAR\n      - name: GENERATED_FILENAME\n        expr: GENERATED_FILENAME\n        data_type: VARCHAR\n      - name: SFTP_DIRECTORY_PATH\n        expr: SFTP_DIRECTORY_PATH\n        data_type: VARCHAR\n    time_dimensions:\n      - name: BATCH_TIMESTAMP\n        expr: BATCH_TIMESTAMP\n        data_type: TIMESTAMP_NTZ\n      - name: UPLOAD_TIMESTAMP\n        expr: UPLOAD_TIMESTAMP\n        data_type: TIMESTAMP_NTZ\n  - name: PIPELINE_LATENCY_ANALYSIS\n    base_table:\n      database: DEDEMO\n      schema: GAMING\n      table: PIPELINE_LATENCY_ANALYSIS\n    dimensions:\n      - name: STAGE_ORDER\n        expr: STAGE_ORDER\n        data_type: NUMBER\n      - name: STAGE\n        expr: STAGE\n        data_type: VARCHAR\n      - name: MAX_SEC\n        expr: MAX_SEC\n        data_type: NUMBER\n      - name: SAMPLES\n        expr: SAMPLES\n        data_type: NUMBER\n    facts:\n      - name: AVG_SEC\n        expr: AVG_SEC\n        data_type: NUMBER\n  - name: OPENFLOW_ERROR_SUMMARY\n    base_table:\n      database: DEDEMO\n      schema: GAMING\n      table: OPENFLOW_ERROR_SUMMARY\n    dimensions:\n      - name: LOG_LEVEL\n        expr: LOG_LEVEL\n        data_type: VARCHAR\n      - name: PROCESS_GROUP\n        expr: PROCESS_GROUP\n        data_type: VARCHAR\n      - name: ERROR_COUNT\n        expr: ERROR_COUNT\n        data_type: NUMBER\n      - name: UNIQUE_ERRORS\n        expr: UNIQUE_ERRORS\n        data_type: NUMBER\n    time_dimensions:\n      - name: HOUR\n        expr: HOUR\n        data_type: TIMESTAMP_NTZ\nverified_queries:\n  - name: 0;1\n    question: What are the recent regulatory batch processing details and performance\n      over the past week?\n    sql: SELECT BATCH_ID, STATUS, TRANSACTION_COUNT, BATCH_TIMESTAMP, UPLOAD_TIMESTAMP,\n      DATEDIFF(SECOND, BATCH_TIMESTAMP, UPLOAD_TIMESTAMP) AS PROCESSING_TIME_SEC FROM\n      regulatory_batches WHERE BATCH_TIMESTAMP > DATEADD(DAY, -7, CURRENT_TIMESTAMP())\n      ORDER BY BATCH_TIMESTAMP DESC\n    verified_at: 1768739767\n    verified_by: Semantic Model Generator\n  - name: 1;1\n    question: What is the performance breakdown of regulatory batches processed in\n      the last 24 hours by status?\n    sql: SELECT STATUS, COUNT(*) AS BATCH_COUNT, SUM(TRANSACTION_COUNT) AS TOTAL_TRANSACTIONS,\n      AVG(TRANSACTION_COUNT) AS AVG_BATCH_SIZE FROM regulatory_batches WHERE BATCH_TIMESTAMP\n      > DATEADD(DAY, -1, CURRENT_TIMESTAMP()) GROUP BY STATUS\n    verified_at: 1768739767\n    verified_by: Semantic Model Generator\n  - name: 2;1\n    question: What are the average and maximum processing times for each stage of\n      the gaming regulatory pipeline?\n    sql: SELECT STAGE, AVG_SEC, MAX_SEC FROM pipeline_latency_analysis ORDER BY STAGE_ORDER\n    verified_at: 1768739767\n    verified_by: Semantic Model Generator\n  - name: 3;1\n    question: What are the recent error patterns in our gaming data pipeline over\n      the last 24 hours?\n    sql: SELECT HOUR, LOG_LEVEL, PROCESS_GROUP, ERROR_COUNT, UNIQUE_ERRORS FROM openflow_error_summary\n      WHERE HOUR > DATEADD(DAY, -1, CURRENT_TIMESTAMP()) ORDER BY HOUR DESC\n    verified_at: 1768739767\n    verified_by: Semantic Model Generator\n  - name: 4;1\n    question: How many regulatory batches were created and transactions processed\n      by hour over the last 24 hours?\n    sql: SELECT DATE_TRUNC('HOUR', BATCH_TIMESTAMP) AS HOUR, COUNT(*) AS BATCHES_CREATED,\n      SUM(TRANSACTION_COUNT) AS TRANSACTIONS_PROCESSED FROM regulatory_batches WHERE\n      BATCH_TIMESTAMP > DATEADD(DAY, -1, CURRENT_TIMESTAMP()) GROUP BY 1 ORDER BY\n      1 DESC\n    verified_at: 1768739767\n    verified_by: Semantic Model Generator\n",
  "warnings": [],
  "errors": []
}